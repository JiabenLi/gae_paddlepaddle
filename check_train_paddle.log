C:\ProgramData\Anaconda3\envs\pp\python.exe C:/Users/root/PycharmProjects/gae_paddlepaddle/gae/train.py
Using citeseer dataset
Epoch: 0001 train_loss= 1.71921 val_ap= 0.68965 time= 1.12225
Epoch: 0002 train_loss= 1.40377 val_ap= 0.69438 time= 0.98724
Epoch: 0003 train_loss= 1.22076 val_ap= 0.69052 time= 0.83019
Epoch: 0004 train_loss= 1.06533 val_ap= 0.69898 time= 0.81325
Epoch: 0005 train_loss= 0.95492 val_ap= 0.71189 time= 0.80518
Epoch: 0006 train_loss= 0.84318 val_ap= 0.73880 time= 0.78018
Epoch: 0007 train_loss= 0.77777 val_ap= 0.76517 time= 0.76317
Epoch: 0008 train_loss= 0.72051 val_ap= 0.78983 time= 0.76017
Epoch: 0009 train_loss= 0.66302 val_ap= 0.80365 time= 0.75817
Epoch: 0010 train_loss= 0.63172 val_ap= 0.79380 time= 0.76122
Epoch: 0011 train_loss= 0.61654 val_ap= 0.79914 time= 0.77253
Epoch: 0012 train_loss= 0.59010 val_ap= 0.81854 time= 0.76719
Epoch: 0013 train_loss= 0.58183 val_ap= 0.82570 time= 0.76116
Epoch: 0014 train_loss= 0.58494 val_ap= 0.83119 time= 0.79818
Epoch: 0015 train_loss= 0.57038 val_ap= 0.83922 time= 0.76618
Epoch: 0016 train_loss= 0.55206 val_ap= 0.84847 time= 0.76717
Epoch: 0017 train_loss= 0.54387 val_ap= 0.85348 time= 0.76924
Epoch: 0018 train_loss= 0.53935 val_ap= 0.85889 time= 0.77816
Epoch: 0019 train_loss= 0.53427 val_ap= 0.86238 time= 0.77019
Epoch: 0020 train_loss= 0.52756 val_ap= 0.86780 time= 0.80116
Epoch: 0021 train_loss= 0.52246 val_ap= 0.87183 time= 0.75717
Epoch: 0022 train_loss= 0.51654 val_ap= 0.87521 time= 0.89022
Epoch: 0023 train_loss= 0.51128 val_ap= 0.87689 time= 0.92920
Epoch: 0024 train_loss= 0.50819 val_ap= 0.87957 time= 1.04724
Epoch: 0025 train_loss= 0.50454 val_ap= 0.88442 time= 0.86718
Epoch: 0026 train_loss= 0.49651 val_ap= 0.88841 time= 1.20227
Epoch: 0027 train_loss= 0.49181 val_ap= 0.88981 time= 1.50334
Epoch: 0028 train_loss= 0.48966 val_ap= 0.89130 time= 1.38635
Epoch: 0029 train_loss= 0.48807 val_ap= 0.89121 time= 1.05835
Epoch: 0030 train_loss= 0.48601 val_ap= 0.89159 time= 1.30139
Epoch: 0031 train_loss= 0.48386 val_ap= 0.89124 time= 1.15367
Epoch: 0032 train_loss= 0.48102 val_ap= 0.89076 time= 1.07337
Epoch: 0033 train_loss= 0.47729 val_ap= 0.88997 time= 1.40530
Epoch: 0034 train_loss= 0.47435 val_ap= 0.88914 time= 1.38063
Epoch: 0035 train_loss= 0.47343 val_ap= 0.88853 time= 0.86819
Epoch: 0036 train_loss= 0.47250 val_ap= 0.88748 time= 0.92520
Epoch: 0037 train_loss= 0.47149 val_ap= 0.88583 time= 0.93022
Epoch: 0038 train_loss= 0.46973 val_ap= 0.88496 time= 1.01624
Epoch: 0039 train_loss= 0.46704 val_ap= 0.88458 time= 1.29931
Epoch: 0040 train_loss= 0.46452 val_ap= 0.88513 time= 1.05224
Epoch: 0041 train_loss= 0.46276 val_ap= 0.88563 time= 1.05669
Epoch: 0042 train_loss= 0.46273 val_ap= 0.88627 time= 1.28329
Epoch: 0043 train_loss= 0.46201 val_ap= 0.88531 time= 1.10332
Epoch: 0044 train_loss= 0.46206 val_ap= 0.88416 time= 1.46431
Epoch: 0045 train_loss= 0.46089 val_ap= 0.88237 time= 0.75220
Epoch: 0046 train_loss= 0.45957 val_ap= 0.88148 time= 1.04123
Epoch: 0047 train_loss= 0.45909 val_ap= 0.88002 time= 0.68217
Epoch: 0048 train_loss= 0.45804 val_ap= 0.87987 time= 1.09123
Epoch: 0049 train_loss= 0.45742 val_ap= 0.88096 time= 1.14926
Epoch: 0050 train_loss= 0.45708 val_ap= 0.88147 time= 1.36433
Epoch: 0051 train_loss= 0.45683 val_ap= 0.88235 time= 1.19427
Epoch: 0052 train_loss= 0.45578 val_ap= 0.88261 time= 1.04224
Epoch: 0053 train_loss= 0.45461 val_ap= 0.88218 time= 1.06024
Epoch: 0054 train_loss= 0.45386 val_ap= 0.88243 time= 0.85219
Epoch: 0055 train_loss= 0.45378 val_ap= 0.88197 time= 1.06645
Epoch: 0056 train_loss= 0.45342 val_ap= 0.88210 time= 1.34930
Epoch: 0057 train_loss= 0.45338 val_ap= 0.88239 time= 0.92921
Epoch: 0058 train_loss= 0.45238 val_ap= 0.88388 time= 1.00423
Epoch: 0059 train_loss= 0.45172 val_ap= 0.88512 time= 0.96099
Epoch: 0060 train_loss= 0.45143 val_ap= 0.88477 time= 0.99321
Epoch: 0061 train_loss= 0.45080 val_ap= 0.88459 time= 1.01525
Epoch: 0062 train_loss= 0.45056 val_ap= 0.88476 time= 0.82218
Epoch: 0063 train_loss= 0.45004 val_ap= 0.88635 time= 1.00323
Epoch: 0064 train_loss= 0.44969 val_ap= 0.88704 time= 0.93420
Epoch: 0065 train_loss= 0.44940 val_ap= 0.88692 time= 1.26228
Epoch: 0066 train_loss= 0.44907 val_ap= 0.88673 time= 1.29129
Epoch: 0067 train_loss= 0.44860 val_ap= 0.88612 time= 1.18927
Epoch: 0068 train_loss= 0.44849 val_ap= 0.88620 time= 0.69514
Epoch: 0069 train_loss= 0.44801 val_ap= 0.88672 time= 0.98055
Epoch: 0070 train_loss= 0.44776 val_ap= 0.88689 time= 0.68215
Epoch: 0071 train_loss= 0.44735 val_ap= 0.88724 time= 1.00524
Epoch: 0072 train_loss= 0.44733 val_ap= 0.88697 time= 0.68115
Epoch: 0073 train_loss= 0.44700 val_ap= 0.88650 time= 0.71315
Epoch: 0074 train_loss= 0.44662 val_ap= 0.88725 time= 0.74817
Epoch: 0075 train_loss= 0.44665 val_ap= 0.88755 time= 0.88757
Epoch: 0076 train_loss= 0.44614 val_ap= 0.88818 time= 0.74423
Epoch: 0077 train_loss= 0.44581 val_ap= 0.88856 time= 1.48313
Epoch: 0078 train_loss= 0.44569 val_ap= 0.88848 time= 0.99521
Epoch: 0079 train_loss= 0.44530 val_ap= 0.88800 time= 1.13525
Epoch: 0080 train_loss= 0.44529 val_ap= 0.88691 time= 1.39271
Epoch: 0081 train_loss= 0.44504 val_ap= 0.88761 time= 0.74164
Epoch: 0082 train_loss= 0.44462 val_ap= 0.88853 time= 0.94630
Epoch: 0083 train_loss= 0.44469 val_ap= 0.88965 time= 0.86521
Epoch: 0084 train_loss= 0.44452 val_ap= 0.88984 time= 0.86103
Epoch: 0085 train_loss= 0.44409 val_ap= 0.88907 time= 0.76050
Epoch: 0086 train_loss= 0.44403 val_ap= 0.88823 time= 0.67622
Epoch: 0087 train_loss= 0.44375 val_ap= 0.88853 time= 1.06025
Epoch: 0088 train_loss= 0.44343 val_ap= 0.88953 time= 0.82219
Epoch: 0089 train_loss= 0.44372 val_ap= 0.88990 time= 0.75015
Epoch: 0090 train_loss= 0.44301 val_ap= 0.89032 time= 0.77217
Epoch: 0091 train_loss= 0.44278 val_ap= 0.88998 time= 0.98323
Epoch: 0092 train_loss= 0.44287 val_ap= 0.88977 time= 0.80975
Epoch: 0093 train_loss= 0.44264 val_ap= 0.89012 time= 0.66215
Epoch: 0094 train_loss= 0.44225 val_ap= 0.89053 time= 0.99213
Epoch: 0095 train_loss= 0.44233 val_ap= 0.89074 time= 0.91721
Epoch: 0096 train_loss= 0.44203 val_ap= 0.89096 time= 1.03025
Epoch: 0097 train_loss= 0.44196 val_ap= 0.89061 time= 0.83965
Epoch: 0098 train_loss= 0.44173 val_ap= 0.89099 time= 1.04624
Epoch: 0099 train_loss= 0.44151 val_ap= 0.89161 time= 0.78719
Epoch: 0100 train_loss= 0.44152 val_ap= 0.89217 time= 0.69114
Epoch: 0101 train_loss= 0.44122 val_ap= 0.89222 time= 0.77218
Epoch: 0102 train_loss= 0.44128 val_ap= 0.89235 time= 0.73216
Epoch: 0103 train_loss= 0.44090 val_ap= 0.89238 time= 1.00124
Epoch: 0104 train_loss= 0.44108 val_ap= 0.89325 time= 0.80818
Epoch: 0105 train_loss= 0.44102 val_ap= 0.89371 time= 1.01123
Epoch: 0106 train_loss= 0.44082 val_ap= 0.89435 time= 0.94422
Epoch: 0107 train_loss= 0.44054 val_ap= 0.89395 time= 0.85521
Epoch: 0108 train_loss= 0.44067 val_ap= 0.89358 time= 0.96322
Epoch: 0109 train_loss= 0.44041 val_ap= 0.89437 time= 0.89027
Epoch: 0110 train_loss= 0.44035 val_ap= 0.89487 time= 1.01021
Epoch: 0111 train_loss= 0.44033 val_ap= 0.89477 time= 0.70516
Epoch: 0112 train_loss= 0.43987 val_ap= 0.89435 time= 0.83621
Epoch: 0113 train_loss= 0.43995 val_ap= 0.89459 time= 0.93037
Epoch: 0114 train_loss= 0.43957 val_ap= 0.89550 time= 0.73318
Epoch: 0115 train_loss= 0.43974 val_ap= 0.89574 time= 1.03675
Epoch: 0116 train_loss= 0.43903 val_ap= 0.89587 time= 0.80120
Epoch: 0117 train_loss= 0.43946 val_ap= 0.89551 time= 0.77217
Epoch: 0118 train_loss= 0.43919 val_ap= 0.89495 time= 0.73917
Epoch: 0119 train_loss= 0.43906 val_ap= 0.89584 time= 0.80718
Epoch: 0120 train_loss= 0.43886 val_ap= 0.89621 time= 0.93819
Epoch: 0121 train_loss= 0.43878 val_ap= 0.89620 time= 0.69419
Epoch: 0122 train_loss= 0.43872 val_ap= 0.89576 time= 1.08224
Epoch: 0123 train_loss= 0.43849 val_ap= 0.89543 time= 0.90620
Epoch: 0124 train_loss= 0.43851 val_ap= 0.89585 time= 0.63314
Epoch: 0125 train_loss= 0.43819 val_ap= 0.89592 time= 0.78618
Epoch: 0126 train_loss= 0.43812 val_ap= 0.89647 time= 0.81418
Epoch: 0127 train_loss= 0.43829 val_ap= 0.89713 time= 0.82224
Epoch: 0128 train_loss= 0.43801 val_ap= 0.89659 time= 1.15126
Epoch: 0129 train_loss= 0.43759 val_ap= 0.89671 time= 1.02731
Epoch: 0130 train_loss= 0.43795 val_ap= 0.89659 time= 0.73216
Epoch: 0131 train_loss= 0.43741 val_ap= 0.89633 time= 1.12226
Epoch: 0132 train_loss= 0.43746 val_ap= 0.89672 time= 0.83424
Epoch: 0133 train_loss= 0.43706 val_ap= 0.89714 time= 1.00028
Epoch: 0134 train_loss= 0.43709 val_ap= 0.89750 time= 0.82821
Epoch: 0135 train_loss= 0.43704 val_ap= 0.89764 time= 0.97620
Epoch: 0136 train_loss= 0.43680 val_ap= 0.89748 time= 0.65615
Epoch: 0137 train_loss= 0.43688 val_ap= 0.89749 time= 0.69217
Epoch: 0138 train_loss= 0.43654 val_ap= 0.89777 time= 0.66114
Epoch: 0139 train_loss= 0.43646 val_ap= 0.89821 time= 0.84419
Epoch: 0140 train_loss= 0.43618 val_ap= 0.89883 time= 0.72618
Epoch: 0141 train_loss= 0.43632 val_ap= 0.89898 time= 1.03923
Epoch: 0142 train_loss= 0.43613 val_ap= 0.89913 time= 0.89920
Epoch: 0143 train_loss= 0.43602 val_ap= 0.89938 time= 0.81318
Epoch: 0144 train_loss= 0.43576 val_ap= 0.90007 time= 0.79016
Epoch: 0145 train_loss= 0.43567 val_ap= 0.90029 time= 1.35633
Epoch: 0146 train_loss= 0.43556 val_ap= 0.89960 time= 1.18425
Epoch: 0147 train_loss= 0.43557 val_ap= 0.89974 time= 0.89222
Epoch: 0148 train_loss= 0.43551 val_ap= 0.90092 time= 1.12924
Epoch: 0149 train_loss= 0.43531 val_ap= 0.90123 time= 0.68518
Epoch: 0150 train_loss= 0.43518 val_ap= 0.90060 time= 0.72717
Epoch: 0151 train_loss= 0.43521 val_ap= 0.90070 time= 0.67115
Epoch: 0152 train_loss= 0.43510 val_ap= 0.90158 time= 0.68120
Epoch: 0153 train_loss= 0.43531 val_ap= 0.90145 time= 0.90922
Epoch: 0154 train_loss= 0.43479 val_ap= 0.90041 time= 1.25432
Epoch: 0155 train_loss= 0.43488 val_ap= 0.90055 time= 0.82708
Epoch: 0156 train_loss= 0.43455 val_ap= 0.90178 time= 0.86619
Epoch: 0157 train_loss= 0.43502 val_ap= 0.90223 time= 0.84023
Epoch: 0158 train_loss= 0.43434 val_ap= 0.90164 time= 0.67214
Epoch: 0159 train_loss= 0.43479 val_ap= 0.90008 time= 0.67815
Epoch: 0160 train_loss= 0.43436 val_ap= 0.90022 time= 0.73218
Epoch: 0161 train_loss= 0.43439 val_ap= 0.90131 time= 0.71368
Epoch: 0162 train_loss= 0.43440 val_ap= 0.90223 time= 0.97474
Epoch: 0163 train_loss= 0.43430 val_ap= 0.90169 time= 0.76617
Epoch: 0164 train_loss= 0.43431 val_ap= 0.90026 time= 1.12626
Epoch: 0165 train_loss= 0.43396 val_ap= 0.90012 time= 1.25728
Epoch: 0166 train_loss= 0.43426 val_ap= 0.90080 time= 1.38323
Epoch: 0167 train_loss= 0.43391 val_ap= 0.89998 time= 1.39431
Epoch: 0168 train_loss= 0.43396 val_ap= 0.90028 time= 1.28027
Epoch: 0169 train_loss= 0.43384 val_ap= 0.90094 time= 1.29231
Epoch: 0170 train_loss= 0.43383 val_ap= 0.90080 time= 1.26329
Epoch: 0171 train_loss= 0.43395 val_ap= 0.90023 time= 1.38431
Epoch: 0172 train_loss= 0.43351 val_ap= 0.89986 time= 1.27528
Epoch: 0173 train_loss= 0.43341 val_ap= 0.90005 time= 1.47233
Epoch: 0174 train_loss= 0.43364 val_ap= 0.90008 time= 1.23329
Epoch: 0175 train_loss= 0.43357 val_ap= 0.90006 time= 1.42132
Epoch: 0176 train_loss= 0.43346 val_ap= 0.90039 time= 1.32830
Epoch: 0177 train_loss= 0.43323 val_ap= 0.89989 time= 1.25927
Epoch: 0178 train_loss= 0.43351 val_ap= 0.89957 time= 1.29480
Epoch: 0179 train_loss= 0.43311 val_ap= 0.89993 time= 1.35030
Epoch: 0180 train_loss= 0.43331 val_ap= 0.90011 time= 1.27829
Epoch: 0181 train_loss= 0.43315 val_ap= 0.90027 time= 1.51717
Epoch: 0182 train_loss= 0.43328 val_ap= 0.90018 time= 1.29444
Epoch: 0183 train_loss= 0.43295 val_ap= 0.89977 time= 1.38731
Epoch: 0184 train_loss= 0.43294 val_ap= 0.89950 time= 1.23133
Epoch: 0185 train_loss= 0.43296 val_ap= 0.90004 time= 1.46845
Epoch: 0186 train_loss= 0.43288 val_ap= 0.90010 time= 1.33431
Epoch: 0187 train_loss= 0.43289 val_ap= 0.90053 time= 1.22327
Epoch: 0188 train_loss= 0.43268 val_ap= 0.90065 time= 1.21172
Epoch: 0189 train_loss= 0.43275 val_ap= 0.89965 time= 1.42541
Epoch: 0190 train_loss= 0.43284 val_ap= 0.89943 time= 1.27118
Epoch: 0191 train_loss= 0.43258 val_ap= 0.89941 time= 1.36159
Epoch: 0192 train_loss= 0.43285 val_ap= 0.90002 time= 1.21828
Epoch: 0193 train_loss= 0.43245 val_ap= 0.90022 time= 1.33531
Epoch: 0194 train_loss= 0.43301 val_ap= 0.89964 time= 1.28128
Epoch: 0195 train_loss= 0.43249 val_ap= 0.89910 time= 1.26630
Epoch: 0196 train_loss= 0.43258 val_ap= 0.89909 time= 1.23327
Epoch: 0197 train_loss= 0.43256 val_ap= 0.89959 time= 1.29229
Epoch: 0198 train_loss= 0.43238 val_ap= 0.89976 time= 1.34030
Epoch: 0199 train_loss= 0.43253 val_ap= 0.89863 time= 1.28266
Epoch: 0200 train_loss= 0.43258 val_ap= 0.89855 time= 1.45832
Optimization Finished!
Test ROC score: 0.9184977659702935
Test AP score: 0.9309075110105105